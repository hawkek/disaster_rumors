{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f5f61aa",
   "metadata": {},
   "source": [
    "# Accessing the CREDBANK Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9dd1510",
   "metadata": {},
   "source": [
    "The CREDBANK dataset is a large collection of tweets relating to events that occurred between mid October 2014 and end of February 2015, which were assessed for veracity by crowdworkers through Mechanical Turk (Turkers). The data are publicly available  [here](https://github.com/compsocial/CREDBANK-data#readme), along with a detailed description of the data.\n",
    "\n",
    "#### The dataset was developed through 4 steps, each with a corresponding CSV file, available for download:\n",
    "1. ##### Streaming Tweet File - stream_tweets_byTimestamp.data:\n",
    "    169 million tweets collected from within the aforementioned time interval. \n",
    "2. ##### Topic File - eventNonEvent_annotations.data: \n",
    "    62,000 tweet topics, which were generated from the above raw tweet stream using automated topic modeling (LDA). Each topic is characterized by a list of 3 topic terms. Each topic is also rated by Turkers as being an event (class 1) or non-event (class 0).\n",
    "3. ##### Credibility Annotation File - cred_event_TurkRatings.data: \n",
    "    1,378 tweet topics that were categorized as events through the process described in #2, above. Each topic was evaluated by 10 Turkers, and was counted as an event if a majority (6/10) assigned it a value of 1. Each of these event topics were then evaluated for credibility by 30 Turkers, each scoring it on a scale ranging from -2 (least credible) to +2 (most credible). \n",
    "4. ##### Searched Tweet File - cred_event_SearchTweets.data: \n",
    "    80 million tweets grouped by the 1,378 event topics from #3, above. Tweets corresponding to each event topic were extracted using the 3 topic terms to form an 'AND' query.\n",
    "\n",
    "For our analysis we use only files #3 and #4, to produce a dataset of roughly 13 million individual tweets, that are grouped into event topics and rated for credibility by 30 Turkers. That is, each tweet is given the credibility score corresponding to its event topic. We roughly follow the data preparation process described by Buntain & Golbeck (2017), whereby each tweet is given an aggregate credibility score that is the mean of 30 individual Turker scores. We then use only the top and bottom deciles of scores, to help ensure that the event topics we include have greater Turker consensus, and are therefore more likely to truly belong to the negative or positive class. We then take further measures to select a sample of these data for modeling as we faced time and computational constraints. This processed is outlined through the following annotated python code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1918801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import pandas as pd, numpy as np\n",
    "import re\n",
    "\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3274347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv containing all tweets in dataset, grouped into topics.\n",
    "# note, this file is 6.12 GB and is too large to store in github repo.\n",
    "# to import, access these data as described above \n",
    "# and save 'cred_event_SearchTweets.data' into your local datasets folder.\n",
    "\n",
    "data = pd.read_csv('../datasets/cred_event_SearchTweets.data', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d227fdfc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1377, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_key</th>\n",
       "      <th>topic_terms</th>\n",
       "      <th>tweet_count</th>\n",
       "      <th>ListOf_tweetid_author_createdAt_tuple</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>host_patrick_neil-20141015_161647-20141015_172214</td>\n",
       "      <td>host,patrick,neil</td>\n",
       "      <td>34694</td>\n",
       "      <td>[('ID=522759240817971202', 'AUTHOR=i_Celeb_Gos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>royals_game_series-20141015_203526-20141015_21...</td>\n",
       "      <td>royals,game,series</td>\n",
       "      <td>22111</td>\n",
       "      <td>[('ID=522782817538043906', 'AUTHOR=topOrioles'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>giants_game_win-20141015_230140-20141016_000502</td>\n",
       "      <td>giants,game,win</td>\n",
       "      <td>9990</td>\n",
       "      <td>[('ID=522861714363015169', 'AUTHOR=GiterDoneSp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>october_ebola_house-20141015_230140-20141016_0...</td>\n",
       "      <td>october,ebola,house</td>\n",
       "      <td>147</td>\n",
       "      <td>[('ID=522863310086373378', 'AUTHOR=lumworld', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ebola_white_health-20141016_012559-20141016_03...</td>\n",
       "      <td>ebola,white,health</td>\n",
       "      <td>2956</td>\n",
       "      <td>[('ID=522797534054711298', 'AUTHOR=HJIrwin', '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           topic_key          topic_terms  \\\n",
       "0  host_patrick_neil-20141015_161647-20141015_172214    host,patrick,neil   \n",
       "1  royals_game_series-20141015_203526-20141015_21...   royals,game,series   \n",
       "2    giants_game_win-20141015_230140-20141016_000502      giants,game,win   \n",
       "3  october_ebola_house-20141015_230140-20141016_0...  october,ebola,house   \n",
       "4  ebola_white_health-20141016_012559-20141016_03...   ebola,white,health   \n",
       "\n",
       "   tweet_count              ListOf_tweetid_author_createdAt_tuple  \n",
       "0        34694  [('ID=522759240817971202', 'AUTHOR=i_Celeb_Gos...  \n",
       "1        22111  [('ID=522782817538043906', 'AUTHOR=topOrioles'...  \n",
       "2         9990  [('ID=522861714363015169', 'AUTHOR=GiterDoneSp...  \n",
       "3          147  [('ID=522863310086373378', 'AUTHOR=lumworld', ...  \n",
       "4         2956  [('ID=522797534054711298', 'AUTHOR=HJIrwin', '...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first look at data\n",
    "# each row indicates an event topic\n",
    "# last column contains all tweets pertaining to respective event\n",
    "# actual tweet text not provided and must be accessed via Twitter's API\n",
    "# tweet_id, user_id, and create_time provided\n",
    "\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2139d64e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80277783"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# over 80 million total tweets\n",
    "data['tweet_count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc8f0461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1378, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_key</th>\n",
       "      <th>topic_terms</th>\n",
       "      <th>Cred_Ratings</th>\n",
       "      <th>Reasons</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>everything_royals_rain-20141015_161647-2014101...</td>\n",
       "      <td>[u'everything', u'royals', u'rain']</td>\n",
       "      <td>[2, 1, 0, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 0, 1, ...</td>\n",
       "      <td>['Game suspended due to rain', 'It is true tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>host_patrick_neil-20141015_161647-20141015_172214</td>\n",
       "      <td>[u'host', u'patrick', u'neil']</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "      <td>['Neil Patrick Harris will host the 2015 Oscar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>royals_game_series-20141015_203526-20141015_21...</td>\n",
       "      <td>[u'royals', u'game', u'series']</td>\n",
       "      <td>[2, 1, 2, 2, 2, 0, 2, 2, 1, 2, 2, 2, 2, 1, 2, ...</td>\n",
       "      <td>['The Royals did win last night and are indeed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>giants_game_win-20141015_230140-20141016_000502</td>\n",
       "      <td>[u'giants', u'game', u'win']</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "      <td>['They did win the game.', 'Major news sources...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>october_ebola_house-20141015_230140-20141016_0...</td>\n",
       "      <td>[u'october', u'ebola', u'house']</td>\n",
       "      <td>[1, 2, 2, 1, 2, 1, 1, 2, 2, 1, 0, 2, 1, 2, 1, ...</td>\n",
       "      <td>['Accurate news story, some opinion.', 'USA To...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           topic_key  \\\n",
       "0  everything_royals_rain-20141015_161647-2014101...   \n",
       "1  host_patrick_neil-20141015_161647-20141015_172214   \n",
       "2  royals_game_series-20141015_203526-20141015_21...   \n",
       "3    giants_game_win-20141015_230140-20141016_000502   \n",
       "4  october_ebola_house-20141015_230140-20141016_0...   \n",
       "\n",
       "                           topic_terms  \\\n",
       "0  [u'everything', u'royals', u'rain']   \n",
       "1       [u'host', u'patrick', u'neil']   \n",
       "2      [u'royals', u'game', u'series']   \n",
       "3         [u'giants', u'game', u'win']   \n",
       "4     [u'october', u'ebola', u'house']   \n",
       "\n",
       "                                        Cred_Ratings  \\\n",
       "0  [2, 1, 0, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 0, 1, ...   \n",
       "1  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n",
       "2  [2, 1, 2, 2, 2, 0, 2, 2, 1, 2, 2, 2, 2, 1, 2, ...   \n",
       "3  [2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, ...   \n",
       "4  [1, 2, 2, 1, 2, 1, 1, 2, 2, 1, 0, 2, 1, 2, 1, ...   \n",
       "\n",
       "                                             Reasons  \n",
       "0  ['Game suspended due to rain', 'It is true tha...  \n",
       "1  ['Neil Patrick Harris will host the 2015 Oscar...  \n",
       "2  ['The Royals did win last night and are indeed...  \n",
       "3  ['They did win the game.', 'Major news sources...  \n",
       "4  ['Accurate news story, some opinion.', 'USA To...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read csv containing credibility scores for each topic\n",
    "# each topic is given a credibility rating by 30 evaluators, each score provided in Cred_Ratings\n",
    "# as well, each evaluators gave a brief note justifying their rating, found in Ratings column.\n",
    "\n",
    "# code modified from \n",
    "# https://stackoverflow.com/questions/32742976/how-to-read-a-column-of-csv-as-dtype-list-using-pandas\n",
    "\n",
    "df_topic_cred = pd.read_csv('../datasets/cred_event_TurkRatings.data',\n",
    "                            sep='\\t',\n",
    "                            converters={'Cred_Ratings':literal_eval})\n",
    "\n",
    "print(df_topic_cred.shape)\n",
    "df_topic_cred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a5caa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# credibility scores are vectors of scores from 30 evaluators\n",
    "# mean score calculated for each topic\n",
    "\n",
    "# this is the aggregation method from Buntain & Golbeck, 2017\n",
    "# https://arxiv.org/pdf/1705.01613.pdf\n",
    "\n",
    "cred_mean = []\n",
    "for i, score in enumerate(df_topic_cred['Cred_Ratings']):\n",
    "    cred_mean.append(np.mean([int(score) for score in df_topic_cred['Cred_Ratings'][i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13c42db5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7013604591028144"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grand mean is ~1.7\n",
    "np.mean(cred_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e1fa5e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_key</th>\n",
       "      <th>topic_terms</th>\n",
       "      <th>Cred_Ratings</th>\n",
       "      <th>Reasons</th>\n",
       "      <th>cred_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>host_patrick_neil-20141015_161647-20141015_172214</td>\n",
       "      <td>[u'host', u'patrick', u'neil']</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "      <td>['Neil Patrick Harris will host the 2015 Oscar...</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>news_senzo_meyiwa-20141026_162345-20141026_173013</td>\n",
       "      <td>[u'news', u'senzo', u'meyiwa']</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "      <td>[\"it's a  Senzo Meyiwa South Africa's internat...</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>patriots_east_afc-20141214_152337-20141214_162911</td>\n",
       "      <td>[u'patriots', u'east', u'afc']</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "      <td>['I saw the game highlights and the division s...</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1342</th>\n",
       "      <td>bowl_pro_odell-20150125_184901-20150125_184943...</td>\n",
       "      <td>[u'bowl', u'pro', u'odell']</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "      <td>['This event is certainly accurate.In Pro Bowl...</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>paris_attack_news-20150107_100842-20150107_112852</td>\n",
       "      <td>[u'paris', u'attack', u'news']</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "      <td>['Multiple sources.', 'Many reputable sources ...</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ebola_obama_#ebola-20141016_181953-20141016_19...</td>\n",
       "      <td>[u'ebola', u'obama', u'#ebola']</td>\n",
       "      <td>[1, 0, 2, 2, 2, -2, -2, 2, 2, 2, 1, -2, 2, 2, ...</td>\n",
       "      <td>['obama wants to intensify action against ebol...</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>killed_hostage_isis-20150206_144013-20150206_1...</td>\n",
       "      <td>[u'killed', u'hostage', u'isis']</td>\n",
       "      <td>[2, 0, 2, 0, 2, -1, 2, 1, 1, -1, 1, 0, -1, 0, ...</td>\n",
       "      <td>['isis news', 'us hostage killed', 'All tweets...</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>ebola_free_sometimes-20141020_101221-20141020_...</td>\n",
       "      <td>[u'ebola', u'free', u'sometimes']</td>\n",
       "      <td>[2, 2, -1, 1, 0, -1, 0, 2, -2, 0, 2, -1, -2, 0...</td>\n",
       "      <td>['There are reputable news agencies online rep...</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>check_haha_#grammys-20150208_183650-20150208_1...</td>\n",
       "      <td>[u'check', u'haha', u'#grammys']</td>\n",
       "      <td>[2, 0, -2, 1, 0, 2, -2, 2, 0, -1, 2, 0, -2, 2,...</td>\n",
       "      <td>['The grammys was an event that took place whi...</td>\n",
       "      <td>0.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>baylor_kicker_dead-20150101_161018-20150101_17...</td>\n",
       "      <td>[u'baylor', u'kicker', u'dead']</td>\n",
       "      <td>[-2, -2, -2, 2, -2, -2, -2, -2, 0, 0, -2, 0, -...</td>\n",
       "      <td>['The Baylor kicker tweeted to refute that he ...</td>\n",
       "      <td>-0.733333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1378 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              topic_key  \\\n",
       "1     host_patrick_neil-20141015_161647-20141015_172214   \n",
       "133   news_senzo_meyiwa-20141026_162345-20141026_173013   \n",
       "356   patriots_east_afc-20141214_152337-20141214_162911   \n",
       "1342  bowl_pro_odell-20150125_184901-20150125_184943...   \n",
       "717   paris_attack_news-20150107_100842-20150107_112852   \n",
       "...                                                 ...   \n",
       "11    ebola_obama_#ebola-20141016_181953-20141016_19...   \n",
       "999   killed_hostage_isis-20150206_144013-20150206_1...   \n",
       "60    ebola_free_sometimes-20141020_101221-20141020_...   \n",
       "1021  check_haha_#grammys-20150208_183650-20150208_1...   \n",
       "610   baylor_kicker_dead-20150101_161018-20150101_17...   \n",
       "\n",
       "                            topic_terms  \\\n",
       "1        [u'host', u'patrick', u'neil']   \n",
       "133      [u'news', u'senzo', u'meyiwa']   \n",
       "356      [u'patriots', u'east', u'afc']   \n",
       "1342        [u'bowl', u'pro', u'odell']   \n",
       "717      [u'paris', u'attack', u'news']   \n",
       "...                                 ...   \n",
       "11      [u'ebola', u'obama', u'#ebola']   \n",
       "999    [u'killed', u'hostage', u'isis']   \n",
       "60    [u'ebola', u'free', u'sometimes']   \n",
       "1021   [u'check', u'haha', u'#grammys']   \n",
       "610     [u'baylor', u'kicker', u'dead']   \n",
       "\n",
       "                                           Cred_Ratings  \\\n",
       "1     [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n",
       "133   [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n",
       "356   [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n",
       "1342  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n",
       "717   [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n",
       "...                                                 ...   \n",
       "11    [1, 0, 2, 2, 2, -2, -2, 2, 2, 2, 1, -2, 2, 2, ...   \n",
       "999   [2, 0, 2, 0, 2, -1, 2, 1, 1, -1, 1, 0, -1, 0, ...   \n",
       "60    [2, 2, -1, 1, 0, -1, 0, 2, -2, 0, 2, -1, -2, 0...   \n",
       "1021  [2, 0, -2, 1, 0, 2, -2, 2, 0, -1, 2, 0, -2, 2,...   \n",
       "610   [-2, -2, -2, 2, -2, -2, -2, -2, 0, 0, -2, 0, -...   \n",
       "\n",
       "                                                Reasons  cred_score  \n",
       "1     ['Neil Patrick Harris will host the 2015 Oscar...    2.000000  \n",
       "133   [\"it's a  Senzo Meyiwa South Africa's internat...    2.000000  \n",
       "356   ['I saw the game highlights and the division s...    2.000000  \n",
       "1342  ['This event is certainly accurate.In Pro Bowl...    2.000000  \n",
       "717   ['Multiple sources.', 'Many reputable sources ...    2.000000  \n",
       "...                                                 ...         ...  \n",
       "11    ['obama wants to intensify action against ebol...    0.666667  \n",
       "999   ['isis news', 'us hostage killed', 'All tweets...    0.633333  \n",
       "60    ['There are reputable news agencies online rep...    0.600000  \n",
       "1021  ['The grammys was an event that took place whi...    0.466667  \n",
       "610   ['The Baylor kicker tweeted to refute that he ...   -0.733333  \n",
       "\n",
       "[1378 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new column for mean cred score for each topic\n",
    "df_topic_cred['cred_score'] = cred_mean\n",
    "\n",
    "df_topic_cred.sort_values('cred_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79a6f54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging both dataframes so that cred score and raw tweets are combined\n",
    "data_merged = pd.merge(left=data, right=df_topic_cred, on= 'topic_key').drop(columns=['topic_terms_y',\n",
    "                                                                              'Cred_Ratings',\n",
    "                                                                              'Reasons'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f0005214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming columns for ease and clarity\n",
    "data_merged.rename(columns={'topic_terms_x':'topic_terms',\n",
    "                     'ListOf_tweetid_author_createdAt_tuple':'topic_tweets'},\n",
    "            inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf5c74de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    122\n",
       "1    102\n",
       "Name: cred_score, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we need to convert cred_score to a dummy variable.\n",
    "# Buntain & Golbeck (2017) used credibility means in the upper and lower 15% to define positive and negative classes.\n",
    "# due to limited computation power we opt for a smaller dataset, and so narrow the range.\n",
    "# we set cred_score to 1 if in upper 10% of mean credibility values, and to 0 if in lower 10%.\n",
    "\n",
    "data_classed = data_merged[~data_merged.cred_score.between(data_merged.cred_score.quantile(0.10),data_merged.cred_score.quantile(0.90))].reset_index(drop=True)\n",
    "data_classed['cred_score'] = [1 if i > 1.5 else 0 for i in data_classed.cred_score]\n",
    "\n",
    "# this produces 122 topics in the negative class (rumour) and 102 topics in the positive class (valid).\n",
    "data_classed.cred_score.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f1bd456",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_key</th>\n",
       "      <th>topic_terms</th>\n",
       "      <th>tweet_count</th>\n",
       "      <th>topic_tweets</th>\n",
       "      <th>cred_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>host_patrick_neil-20141015_161647-20141015_172214</td>\n",
       "      <td>host,patrick,neil</td>\n",
       "      <td>34694</td>\n",
       "      <td>[('ID=522759240817971202', 'AUTHOR=i_Celeb_Gos...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>october_ebola_house-20141015_230140-20141016_0...</td>\n",
       "      <td>october,ebola,house</td>\n",
       "      <td>147</td>\n",
       "      <td>[('ID=522863310086373378', 'AUTHOR=lumworld', ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oscar_pistorius_because-20141016_044421-201410...</td>\n",
       "      <td>oscar,pistorius,because</td>\n",
       "      <td>446</td>\n",
       "      <td>[('ID=522827406432669696', 'AUTHOR=Honeyy_Khan...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>artist_vote_year-20141016_111453-20141016_121002</td>\n",
       "      <td>artist,vote,year</td>\n",
       "      <td>66473</td>\n",
       "      <td>[('ID=522936371779239937', 'AUTHOR=60sDinerLou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>story_october_ebola-20141016_111453-20141016_1...</td>\n",
       "      <td>story,october,ebola</td>\n",
       "      <td>328</td>\n",
       "      <td>[('ID=522924216291569665', 'AUTHOR=October_14t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>costa_diego_charged-20150128_121053-20150128_1...</td>\n",
       "      <td>costa,diego,charged</td>\n",
       "      <td>17310</td>\n",
       "      <td>[('ID=560615461503926272', 'AUTHOR=jakieboyhah...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>ebola_#ebola_travel-20141016_131147-20141016_1...</td>\n",
       "      <td>ebola,#ebola,travel</td>\n",
       "      <td>27796</td>\n",
       "      <td>[('ID=522978106181951488', 'AUTHOR=BINGBINGDEL...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>ebola_news_over-20141016_131147-20141016_14162...</td>\n",
       "      <td>ebola,news,over</td>\n",
       "      <td>25389</td>\n",
       "      <td>[('ID=523047031120879616', 'AUTHOR=757LiveNG',...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>god_golden_awards-20150115_101528-20150115_104...</td>\n",
       "      <td>god,golden,awards</td>\n",
       "      <td>2372</td>\n",
       "      <td>[('ID=556571788638179328', 'AUTHOR=MikeysMocha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>streak_hawks_game-20150202_215501-20150202_220...</td>\n",
       "      <td>streak,hawks,game</td>\n",
       "      <td>9069</td>\n",
       "      <td>[('ID=562594691363786753', 'AUTHOR=_jvrod', 'C...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>224 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             topic_key  \\\n",
       "0    host_patrick_neil-20141015_161647-20141015_172214   \n",
       "1    october_ebola_house-20141015_230140-20141016_0...   \n",
       "2    oscar_pistorius_because-20141016_044421-201410...   \n",
       "3     artist_vote_year-20141016_111453-20141016_121002   \n",
       "4    story_october_ebola-20141016_111453-20141016_1...   \n",
       "..                                                 ...   \n",
       "219  costa_diego_charged-20150128_121053-20150128_1...   \n",
       "220  ebola_#ebola_travel-20141016_131147-20141016_1...   \n",
       "221  ebola_news_over-20141016_131147-20141016_14162...   \n",
       "222  god_golden_awards-20150115_101528-20150115_104...   \n",
       "223  streak_hawks_game-20150202_215501-20150202_220...   \n",
       "\n",
       "                 topic_terms  tweet_count  \\\n",
       "0          host,patrick,neil        34694   \n",
       "1        october,ebola,house          147   \n",
       "2    oscar,pistorius,because          446   \n",
       "3           artist,vote,year        66473   \n",
       "4        story,october,ebola          328   \n",
       "..                       ...          ...   \n",
       "219      costa,diego,charged        17310   \n",
       "220      ebola,#ebola,travel        27796   \n",
       "221          ebola,news,over        25389   \n",
       "222        god,golden,awards         2372   \n",
       "223        streak,hawks,game         9069   \n",
       "\n",
       "                                          topic_tweets  cred_score  \n",
       "0    [('ID=522759240817971202', 'AUTHOR=i_Celeb_Gos...           1  \n",
       "1    [('ID=522863310086373378', 'AUTHOR=lumworld', ...           0  \n",
       "2    [('ID=522827406432669696', 'AUTHOR=Honeyy_Khan...           0  \n",
       "3    [('ID=522936371779239937', 'AUTHOR=60sDinerLou...           0  \n",
       "4    [('ID=522924216291569665', 'AUTHOR=October_14t...           0  \n",
       "..                                                 ...         ...  \n",
       "219  [('ID=560615461503926272', 'AUTHOR=jakieboyhah...           1  \n",
       "220  [('ID=522978106181951488', 'AUTHOR=BINGBINGDEL...           0  \n",
       "221  [('ID=523047031120879616', 'AUTHOR=757LiveNG',...           0  \n",
       "222  [('ID=556571788638179328', 'AUTHOR=MikeysMocha...           0  \n",
       "223  [('ID=562594691363786753', 'AUTHOR=_jvrod', 'C...           1  \n",
       "\n",
       "[224 rows x 5 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looking at dataset\n",
    "data_classed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "55621683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to structure the data with individual tweets as rows in rows, and topics as attributes.\n",
    "# define function to read each string in 'topic_tweets' and convert into nested list of individual tweets\n",
    "\n",
    "def tweets_to_list(topic_tweets):\n",
    "    col_list = re.findall(r\"(?<=ID=)\\d+|(?<=AUTHOR=)(?!ID=)\\w*|(?<=CreatedAt=)(?!AUTHOR=)(?!ID=)[\\d-]*\\s[\\d:]*\",\n",
    "                    topic_tweets,\n",
    "                    re.MULTILINE)\n",
    "    \n",
    "    nested_list = []\n",
    "    for i in range(0,len(col_list),3):\n",
    "            nested_list.append([col_list[i], col_list[i+1], col_list[i+2]])\n",
    "    \n",
    "    return nested_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e01c5d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# iterate through each string in topic_tweets and export into CSVs containing tweets by topic\n",
    "\n",
    "for i, topic in enumerate(data_classed.topic_tweets):\n",
    "    \n",
    "    nested_list = tweets_to_list(topic)\n",
    "    \n",
    "    df = pd.DataFrame(nested_list, columns=['tweet_id','user_id','create_time'])\n",
    "    df['topic_key'] = data_classed['topic_key'][i]\n",
    "    df['is_credible'] = data_classed['cred_score'][i]\n",
    "    df.to_csv(f'../datasets/topic_tweets/topic_{i}.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
