{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14a42ac6",
   "metadata": {},
   "source": [
    "# MODEL 1: DISASTER RELEVANCE VERIFICATION\n",
    "\n",
    "### DATA WRANGLING\n",
    "Using a dataset of tweets provided by [Kaggle](https://www.kaggle.com/jannesklaas/disasters-on-social-media) sourced originally from Figure-Eight (acquired by [Appen](www.appen.com)), a blackbox model based on neural networks was developed.\n",
    "\n",
    "The purpose of the model is to be able to accept any tweet as an input and return a classification of whether the tweet is related to a distaster or not.\n",
    "\n",
    "The data originally had a 3rd classification \"Can't Decide\" along with \"Relevant\" & \"Not Relevant\", therefore all rows with the 3rd classification were removed. The sample size was barely affected as it only dropped from 10876 to 10860.\n",
    "\n",
    "Additionally, the text contents of each tweet underwent extensive cleaning as provided by Kaggle user [georgesaavedra](https://www.kaggle.com/georgesaavedra/best-nlp-disaster-tweets-classifier):\n",
    "- URL & HTML removal\n",
    "- emoji removal\n",
    "- line breaks to spaces\n",
    "- common abbreviations/slang/typos converted to real words\n",
    "- punctuation & number removal (retaining only letters)\n",
    "- lower-cased\n",
    "\n",
    "As neural networks require array inputs, all tweets were tokenized and converted to sequences of max length 60 with padding, if required. Max length 60 was selected as the max length of a tweet is 280 characters which is 55 words on average. \n",
    "\n",
    "To further improve the impact of each word, a pretrained Google News corpus was utilized to create a word embedding matrix where recognized words from all tweets were assigned a weight predetermined by Google. This weight matrix was used for the weight parameter in the embedding input layer of the neural network.\n",
    "\n",
    "### MODELING\n",
    "Through trial and error of numerous neural network implementations, a low-loss, low-variance model was developed with an accuracy of **83%**:\n",
    "- RESULTS: loss: 0.3918 - acc: 0.8354 - val_loss: 0.4055 - val_acc: 0.8310\n",
    "\n",
    "Model composition:\n",
    "- Stochastic Gradient Descent (SGD) optimizer\n",
    "    - Adam resulted in very overfit models with high variance\n",
    "- Embedding input layer\n",
    "- 2 Conv1D layers (32 & 64 filters respectively)\n",
    "- 1 Dense layer (32 filters)\n",
    "- Dense sigmoid output layer \n",
    "    - Batchnomalization + Dropout applied to all layers except output\n",
    "    - AveragePooling1D and GlobalAveragePooling1D (similar to AveragePooling+Flatten) applied to all Conv1D layers\n",
    "    \n",
    "Based the best results from epoch 129/200 were re-loaded and the model was saved to 'pretrained_models/relevance_model.hdf5' for re-use in the web-app.\n",
    "\n",
    "### CONCLUSION\n",
    "Through numerous modifications to the model, including uses of LSTM layers, 83% would be the best performance. Despite this fact, we've concluded that it's okay to have the remaining 17% unaccounted for as tweets that are considered false positive (predicted as relevant, but is not) would end up being classified as misinformation in the 2nd model - the disaster credibility model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d586c991",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, matplotlib.pyplot as plt, seaborn as sns\n",
    "import re\n",
    "import string\n",
    "import gensim\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Embedding, BatchNormalization, Dropout, AveragePooling1D, GlobalAveragePooling1D, Conv1D, Flatten\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "309864a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random seed set for reproduced results\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2620de9",
   "metadata": {},
   "source": [
    "# 1. DATA WRANGLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9648d32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_unit_id</th>\n",
       "      <th>_golden</th>\n",
       "      <th>_unit_state</th>\n",
       "      <th>_trusted_judgments</th>\n",
       "      <th>_last_judgment_at</th>\n",
       "      <th>choose_one</th>\n",
       "      <th>choose_one:confidence</th>\n",
       "      <th>choose_one_gold</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>userid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>778243823</td>\n",
       "      <td>True</td>\n",
       "      <td>golden</td>\n",
       "      <td>156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Relevant</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Relevant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>778243824</td>\n",
       "      <td>True</td>\n",
       "      <td>golden</td>\n",
       "      <td>152</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Relevant</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Relevant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>778243825</td>\n",
       "      <td>True</td>\n",
       "      <td>golden</td>\n",
       "      <td>137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Relevant</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Relevant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>778243826</td>\n",
       "      <td>True</td>\n",
       "      <td>golden</td>\n",
       "      <td>136</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Relevant</td>\n",
       "      <td>0.9603</td>\n",
       "      <td>Relevant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>778243827</td>\n",
       "      <td>True</td>\n",
       "      <td>golden</td>\n",
       "      <td>138</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Relevant</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Relevant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    _unit_id  _golden  ... tweetid  userid\n",
       "0  778243823     True  ...     1.0     NaN\n",
       "1  778243824     True  ...    13.0     NaN\n",
       "2  778243825     True  ...    14.0     NaN\n",
       "3  778243826     True  ...    15.0     NaN\n",
       "4  778243827     True  ...    16.0     NaN\n",
       "\n",
       "[5 rows x 13 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training dataset\n",
    "# from https://www.kaggle.com/jannesklaas/disasters-on-social-media\n",
    "    # sourced from figure-eight, formally Crowdflower, acquired by Appen\n",
    "    \n",
    "train = pd.read_csv('../datasets/disaster_relevance.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efe4e495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retaining only 2 columns\n",
    "train = train[['choose_one', 'text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f377e06e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>choose_one</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Relevant</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  choose_one                                text\n",
       "0   Relevant  Just happened a terrible car crash"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f289e81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "choose_one    0\n",
       "text          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No missing values\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6031982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10876, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Relevant', 'Not Relevant', \"Can't Decide\"], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape & unique targets\n",
    "print(train.shape)\n",
    "train['choose_one'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "129764fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10860, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Relevant', 'Not Relevant'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Omit 'can't decide'\n",
    "train = train[train['choose_one'] != \"Can't Decide\"]\n",
    "print(train.shape)\n",
    "train['choose_one'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76d046ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Just happened a terrible car crash', 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature & target defined\n",
    "X = train['text']\n",
    "y = train['choose_one'].map({'Relevant':1, 'Not Relevant':0})\n",
    "\n",
    "X[0], y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5823edd9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.569705\n",
       "1    0.430295\n",
       "Name: choose_one, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distribution near balanced\n",
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f034c3",
   "metadata": {},
   "source": [
    "### 1.1 INITIAL CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08a2e97d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                       Just happened a terrible car crash\n",
       "1        Our Deeds are the Reason of this #earthquake M...\n",
       "2        Heard about #earthquake is different cities, s...\n",
       "3        there is a forest fire at spot pond, geese are...\n",
       "4                   Forest fire near La Ronge Sask. Canada\n",
       "                               ...                        \n",
       "10871    M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...\n",
       "10872    Police investigating after an e-bike collided ...\n",
       "10873    The Latest: More Homes Razed by Northern Calif...\n",
       "10874    MEG issues Hazardous Weather Outlook (HWO) htt...\n",
       "10875    #CityofCalgary has activated its Municipal Eme...\n",
       "Name: text, Length: 10860, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pre-cleaning\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c35000fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial cleaning\n",
    "\n",
    "def clean(text):\n",
    "    \n",
    "    #URLs\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+','', text)\n",
    "    \n",
    "    #HTMLs\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    \n",
    "    #Emojis\n",
    "    emojis = re.compile(\n",
    "        '['\n",
    "        u'\\U0001F600-\\U0001F64F'  # emoticons\n",
    "        u'\\U0001F300-\\U0001F5FF'  # symbols & pictographs\n",
    "        u'\\U0001F680-\\U0001F6FF'  # transport & map symbols\n",
    "        u'\\U0001F1E0-\\U0001F1FF'  # flags (iOS)\n",
    "        u'\\U00002702-\\U000027B0'\n",
    "        u'\\U000024C2-\\U0001F251'\n",
    "        ']+',\n",
    "        flags=re.UNICODE)\n",
    "    text = emojis.sub(r'', text)\n",
    "    \n",
    "    #Line breaks\n",
    "    text = re.sub(r'\\n', '', text)\n",
    "    \n",
    "    # Alphabets only\n",
    "    text = re.sub(r'[^a-zA-Z ]', '', text)\n",
    "    \n",
    "    return text\n",
    "    \n",
    "X = X.apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c9cc47e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                       Just happened a terrible car crash\n",
       "1        Our Deeds are the Reason of this earthquake Ma...\n",
       "2        Heard about earthquake is different cities sta...\n",
       "3        there is a forest fire at spot pond geese are ...\n",
       "4                    Forest fire near La Ronge Sask Canada\n",
       "                               ...                        \n",
       "10871                        M  UTCkm S of Volcano Hawaii \n",
       "10872    Police investigating after an ebike collided w...\n",
       "10873    The Latest More Homes Razed by Northern Califo...\n",
       "10874            MEG issues Hazardous Weather Outlook HWO \n",
       "10875    CityofCalgary has activated its Municipal Emer...\n",
       "Name: text, Length: 10860, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# post-cleaning round 1\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a5ac613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Secondary cleaner\n",
    "# Twitter cleaner supplied by\n",
    "# https://www.kaggle.com/georgesaavedra/best-nlp-disaster-tweets-classifier\n",
    "\n",
    "def clean2(tweet):\n",
    "  # Acronyms and miswritten words\n",
    "  tweet = re.sub(r\"Typhoon-Devastated\", \"typhoon devastated\", tweet)\n",
    "  tweet = re.sub(r\"TyphoonDevastated\", \"typhoon devastated\", tweet)\n",
    "  tweet = re.sub(r\"typhoondevastated\", \"typhoon devastated\", tweet)\n",
    "  tweet = re.sub(r\"MH370\", \"Malaysia Airlines Flight\", tweet)\n",
    "  tweet = re.sub(r\"MH\", \"Malaysia Airlines Flight\", tweet)\n",
    "  tweet = re.sub(r\"mh370\", \"Malaysia Airlines Flight\", tweet)\n",
    "  tweet = re.sub(r\"year-old\", \"years old\", tweet)\n",
    "  tweet = re.sub(r\"yearold\", \"years old\", tweet)\n",
    "  tweet = re.sub(r\"yr old\", \"years old\", tweet)\n",
    "  tweet = re.sub(r\"PKK\", \"Kurdistan Workers Party\", tweet)\n",
    "  tweet = re.sub(r\"MP\", \"madhya pradesh\", tweet)\n",
    "  tweet = re.sub(r\"rly\", \"railway\", tweet)\n",
    "  tweet = re.sub(r\"CDT\", \"Central Daylight Time\", tweet)\n",
    "  tweet = re.sub(r\"sensorsenso\", \"sensor senso\", tweet)\n",
    "  tweet = re.sub(r\"pm\", \"\", tweet)\n",
    "  tweet = re.sub(r\"PM\", \"\", tweet)\n",
    "  tweet = re.sub(r\"nan\", '', tweet)\n",
    "  tweet = re.sub(r\"terrorismturn\", \"terrorism turn\", tweet)\n",
    "  tweet = re.sub(r\"epicente\", \"epicenter\", tweet)\n",
    "  tweet = re.sub(r\"epicenterr\", \"epicenter\", tweet)\n",
    "  tweet = re.sub(r\"WAwildfire\", \"Washington Wildfire\", tweet)\n",
    "  tweet = re.sub(r\"prebreak\", \"pre break\", tweet)\n",
    "  tweet = re.sub(r\"nowplaying\", \"now playing\", tweet)\n",
    "  tweet = re.sub(r\"RT\", \"retweet\", tweet)\n",
    "  tweet = re.sub(r\"EbolaOutbreak\", \"Ebola Outbreak\", tweet)\n",
    "  tweet = re.sub(r\"LondonFire\", \"London Fire\", tweet)\n",
    "  tweet = re.sub(r\"IDFire\", \"Idaho Fire\", tweet)\n",
    "  tweet = re.sub(r\"withBioterrorism&use\", \"with Bioterrorism & use\", tweet)\n",
    "  tweet = re.sub(r\"NASAHurricane\", \"NASA Hurricane\", tweet)\n",
    "  tweet = re.sub(r\"withweapons\", \"with weapons\", tweet)\n",
    "  tweet = re.sub(r\"NuclearPower\", \"Nuclear Power\", tweet)\n",
    "  tweet = re.sub(r\"WhiteTerrorism\", \"White Terrorism\", tweet)\n",
    "  tweet = re.sub(r\"MyanmarFlood\", \"Myanmar Flood\", tweet)\n",
    "  tweet = re.sub(r\"ExtremeWeather\", \"Extreme Weather\", tweet)\n",
    "\n",
    "  # Special characters\n",
    "  tweet = re.sub(r\"%20\", \"\", tweet)\n",
    "  tweet = re.sub(r\"%\", \"\", tweet)\n",
    "  tweet = re.sub(r\"@\", \"\", tweet)\n",
    "  tweet = re.sub(r\"#\", '', tweet)\n",
    "  tweet = re.sub(r\"'\", '', tweet)\n",
    "  tweet = re.sub(r\"\\x89û_\", '', tweet)\n",
    "  tweet = re.sub(r\"\\x89ûò\", '', tweet)\n",
    "  tweet = re.sub(r\"16yr\", \"16 year\", tweet)\n",
    "  tweet = re.sub(r\"re\\x89û_\", '', tweet)\n",
    "  tweet = re.sub(r\"\\x89û\", '', tweet)\n",
    "  tweet = re.sub(r\"\\x89Û\", '', tweet)\n",
    "  tweet = re.sub(r\"re\\x89Û\", \"re \", tweet)\n",
    "  tweet = re.sub(r\"re\\x89û\", \"re \", tweet)\n",
    "  tweet = re.sub(r\"\\x89ûª\", \"'\", tweet)\n",
    "  tweet = re.sub(r\"\\x89û\", '', tweet)\n",
    "  tweet = re.sub(r\"\\x89ûò\", '', tweet)\n",
    "  tweet = re.sub(r\"\\x89Û_\", \"\", tweet)\n",
    "  tweet = re.sub(r\"\\x89ÛÒ\", \"\", tweet)\n",
    "  tweet = re.sub(r\"\\x89ÛÓ\", \"\", tweet)\n",
    "  tweet = re.sub(r\"\\x89ÛÏWhen\", \"When\", tweet)\n",
    "  tweet = re.sub(r\"\\x89ÛÏ\", \"\", tweet)\n",
    "  tweet = re.sub(r\"China\\x89Ûªs\", \"China's\", tweet)\n",
    "  tweet = re.sub(r\"let\\x89Ûªs\", \"let's\", tweet)\n",
    "  tweet = re.sub(r\"\\x89Û÷\", \"\", tweet)\n",
    "  tweet = re.sub(r\"\\x89Ûª\", \"\", tweet)\n",
    "  tweet = re.sub(r\"\\x89Û\\x9d\", \"\", tweet)\n",
    "  tweet = re.sub(r\"å_\", \"\", tweet)\n",
    "  tweet = re.sub(r\"\\x89Û¢\", \"\", tweet)\n",
    "  tweet = re.sub(r\"\\x89Û¢åÊ\", \"\", tweet)\n",
    "  tweet = re.sub(r\"fromåÊwounds\", \"from wounds\", tweet)\n",
    "  tweet = re.sub(r\"åÊ\", \"\", tweet)\n",
    "  tweet = re.sub(r\"åÈ\", \"\", tweet)\n",
    "  tweet = re.sub(r\"JapÌ_n\", \"Japan\", tweet)    \n",
    "  tweet = re.sub(r\"Ì©\", \"e\", tweet)\n",
    "  tweet = re.sub(r\"å¨\", \"\", tweet)\n",
    "  tweet = re.sub(r\"SuruÌ¤\", \"Suruc\", tweet)\n",
    "  tweet = re.sub(r\"åÇ\", \"\", tweet)\n",
    "  tweet = re.sub(r\"å£3million\", f\"3 million\", tweet)\n",
    "  tweet = re.sub(r\"åÀ\", \"\", tweet)\n",
    "\n",
    "  # Contractions\n",
    "  tweet = re.sub(r\"he's\", \"he is\", tweet)\n",
    "  tweet = re.sub(r\"there's\", \"there is\", tweet)\n",
    "  tweet = re.sub(r\"We're\", \"We are\", tweet)\n",
    "  tweet = re.sub(r\"That's\", \"That is\", tweet)\n",
    "  tweet = re.sub(r\"won't\", \"will not\", tweet)\n",
    "  tweet = re.sub(r\"they're\", \"they are\", tweet)\n",
    "  tweet = re.sub(r\"Can't\", \"Cannot\", tweet)\n",
    "  tweet = re.sub(r\"wasn't\", \"was not\", tweet)\n",
    "  tweet = re.sub(r\"don\\x89Ûªt\", \"do not\", tweet)\n",
    "  tweet = re.sub(r\"aren't\", \"are not\", tweet)\n",
    "  tweet = re.sub(r\"isn't\", \"is not\", tweet)\n",
    "  tweet = re.sub(r\"What's\", \"What is\", tweet)\n",
    "  tweet = re.sub(r\"haven't\", \"have not\", tweet)\n",
    "  tweet = re.sub(r\"hasn't\", \"has not\", tweet)\n",
    "  tweet = re.sub(r\"There's\", \"There is\", tweet)\n",
    "  tweet = re.sub(r\"He's\", \"He is\", tweet)\n",
    "  tweet = re.sub(r\"It's\", \"It is\", tweet)\n",
    "  tweet = re.sub(r\"You're\", \"You are\", tweet)\n",
    "  tweet = re.sub(r\"I'M\", \"I am\", tweet)\n",
    "  tweet = re.sub(r\"Im\", \"I am\", tweet)\n",
    "  tweet = re.sub(r\"shouldn't\", \"should not\", tweet)\n",
    "  tweet = re.sub(r\"wouldn't\", \"would not\", tweet)\n",
    "  tweet = re.sub(r\"i'm\", \"I am\", tweet)\n",
    "  tweet = re.sub(r\"I\\x89Ûªm\", \"I am\", tweet)\n",
    "  tweet = re.sub(r\"I'm\", \"I am\", tweet)\n",
    "  tweet = re.sub(r\"Isn't\", \"is not\", tweet)\n",
    "  tweet = re.sub(r\"Here's\", \"Here is\", tweet)\n",
    "  tweet = re.sub(r\"you've\", \"you have\", tweet)\n",
    "  tweet = re.sub(r\"you\\x89Ûªve\", \"you have\", tweet)\n",
    "  tweet = re.sub(r\"we're\", \"we are\", tweet)\n",
    "  tweet = re.sub(r\"what's\", \"what is\", tweet)\n",
    "  tweet = re.sub(r\"couldn't\", \"could not\", tweet)\n",
    "  tweet = re.sub(r\"we've\", \"we have\", tweet)\n",
    "  tweet = re.sub(r\"it\\x89Ûªs\", \"it is\", tweet)\n",
    "  tweet = re.sub(r\"doesn\\x89Ûªt\", \"does not\", tweet)\n",
    "  tweet = re.sub(r\"It\\x89Ûªs\", \"It is\", tweet)\n",
    "  tweet = re.sub(r\"Here\\x89Ûªs\", \"Here is\", tweet)\n",
    "  tweet = re.sub(r\"who's\", \"who is\", tweet)\n",
    "  tweet = re.sub(r\"I\\x89Ûªve\", \"I have\", tweet)\n",
    "  tweet = re.sub(r\"y'all\", \"you all\", tweet)\n",
    "  tweet = re.sub(r\"can\\x89Ûªt\", \"cannot\", tweet)\n",
    "  tweet = re.sub(r\"would've\", \"would have\", tweet)\n",
    "  tweet = re.sub(r\"it'll\", \"it will\", tweet)\n",
    "  tweet = re.sub(r\"we'll\", \"we will\", tweet)\n",
    "  tweet = re.sub(r\"wouldn\\x89Ûªt\", \"would not\", tweet)\n",
    "  tweet = re.sub(r\"We've\", \"We have\", tweet)\n",
    "  tweet = re.sub(r\"he'll\", \"he will\", tweet)\n",
    "  tweet = re.sub(r\"Y'all\", \"You all\", tweet)\n",
    "  tweet = re.sub(r\"Weren't\", \"Were not\", tweet)\n",
    "  tweet = re.sub(r\"Didn't\", \"Did not\", tweet)\n",
    "  tweet = re.sub(r\"they'll\", \"they will\", tweet)\n",
    "  tweet = re.sub(r\"they'd\", \"they would\", tweet)\n",
    "  tweet = re.sub(r\"DON'T\", \"DO NOT\", tweet)\n",
    "  tweet = re.sub(r\"That\\x89Ûªs\", \"That is\", tweet)\n",
    "  tweet = re.sub(r\"they've\", \"they have\", tweet)\n",
    "  tweet = re.sub(r\"i'd\", \"I would\", tweet)\n",
    "  tweet = re.sub(r\"should've\", \"should have\", tweet)\n",
    "  tweet = re.sub(r\"You\\x89Ûªre\", \"You are\", tweet)\n",
    "  tweet = re.sub(r\"where's\", \"where is\", tweet)\n",
    "  tweet = re.sub(r\"Don\\x89Ûªt\", \"Do not\", tweet)\n",
    "  tweet = re.sub(r\"we'd\", \"we would\", tweet)\n",
    "  tweet = re.sub(r\"i'll\", \"I will\", tweet)\n",
    "  tweet = re.sub(r\"weren't\", \"were not\", tweet)\n",
    "  tweet = re.sub(r\"They're\", \"They are\", tweet)\n",
    "  tweet = re.sub(r\"Can\\x89Ûªt\", \"Cannot\", tweet)\n",
    "  tweet = re.sub(r\"you\\x89Ûªll\", \"you will\", tweet)\n",
    "  tweet = re.sub(r\"I\\x89Ûªd\", \"I would\", tweet)\n",
    "  tweet = re.sub(r\"let's\", \"let us\", tweet)\n",
    "  tweet = re.sub(r\"it's\", \"it is\", tweet)\n",
    "  tweet = re.sub(r\"can't\", \"can not\", tweet)\n",
    "  tweet = re.sub(r\"cant\", \"can not\", tweet)\n",
    "  tweet = re.sub(r\"don't\", \"do not\", tweet)\n",
    "  tweet = re.sub(r\"dont\", \"do not\", tweet)\n",
    "  tweet = re.sub(r\"you're\", \"you are\", tweet)\n",
    "  tweet = re.sub(r\"i've\", \"I have\", tweet)\n",
    "  tweet = re.sub(r\"that's\", \"that is\", tweet)\n",
    "  tweet = re.sub(r\"i'll\", \"I will\", tweet)\n",
    "  tweet = re.sub(r\"doesn't\", \"does not\", tweet)\n",
    "  tweet = re.sub(r\"i'd\", \"I would\", tweet)\n",
    "  tweet = re.sub(r\"didn't\", \"did not\", tweet)\n",
    "  tweet = re.sub(r\"ain't\", \"am not\", tweet)\n",
    "  tweet = re.sub(r\"you'll\", \"you will\", tweet)\n",
    "  tweet = re.sub(r\"I've\", \"I have\", tweet)\n",
    "  tweet = re.sub(r\"Don't\", \"do not\", tweet)\n",
    "  tweet = re.sub(r\"I'll\", \"I will\", tweet)\n",
    "  tweet = re.sub(r\"I'd\", \"I would\", tweet)\n",
    "  tweet = re.sub(r\"Let's\", \"Let us\", tweet)\n",
    "  tweet = re.sub(r\"you'd\", \"You would\", tweet)\n",
    "  tweet = re.sub(r\"It's\", \"It is\", tweet)\n",
    "  tweet = re.sub(r\"Ain't\", \"am not\", tweet)\n",
    "  tweet = re.sub(r\"Haven't\", \"Have not\", tweet)\n",
    "  tweet = re.sub(r\"Could've\", \"Could have\", tweet)\n",
    "  tweet = re.sub(r\"youve\", \"you have\", tweet)  \n",
    "  tweet = re.sub(r\"donå«t\", \"do not\", tweet)\n",
    "\n",
    "  return tweet\n",
    "\n",
    "X = X.apply(clean2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff7934b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                       Just happened a terrible car crash\n",
       "1        Our Deeds are the Reason of this earthquake Ma...\n",
       "2        Heard about earthquake is different cities sta...\n",
       "3        there is a forest fire at spot pond geese are ...\n",
       "4                    Forest fire near La Ronge Sask Canada\n",
       "                               ...                        \n",
       "10871                        M  UTCkm S of Volcano Hawaii \n",
       "10872    Police investigating after an ebike collided w...\n",
       "10873    The Latest More Homes Razed by Northern Califo...\n",
       "10874            MEG issues Hazardous Weather Outlook HWO \n",
       "10875    CityofCalgary has activated its Municipal Emer...\n",
       "Name: text, Length: 10860, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Post-cleaning round 2\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a7fc952f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final cleaning\n",
    "def clean3(text):\n",
    "    \n",
    "    #Punctuations\n",
    "    text = re.sub(r'[%s]' % re.escape(string.punctuation), '', text)\n",
    "    \n",
    "    #Extra white-space\n",
    "    text = re.sub(r' +', ' ', text)\n",
    "    \n",
    "    return text.lower()\n",
    "\n",
    "X = X.apply(clean3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a44251b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                       just happened a terrible car crash\n",
       "1        our deeds are the reason of this earthquake ma...\n",
       "2        heard about earthquake is different cities sta...\n",
       "3        there is a forest fire at spot pond geese are ...\n",
       "4                    forest fire near la ronge sask canada\n",
       "                               ...                        \n",
       "10871                         m utckm s of volcano hawaii \n",
       "10872    police investigating after an ebike collided w...\n",
       "10873    the latest more homes razed by northern califo...\n",
       "10874            meg issues hazardous weather outlook hwo \n",
       "10875    cityofcalgary has activated its municipal emer...\n",
       "Name: text, Length: 10860, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final cleaned text\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d84ecf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    random_state=42, \n",
    "                                                    stratify=y,\n",
    "                                                    test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fe2027c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8688,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6534185",
   "metadata": {},
   "source": [
    "### 1.2 TOKENIZATION & SEQUENCING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ada88456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max words in tokenizer index\n",
    "max_words = 100000\n",
    "\n",
    "# Tokenizer fit, sequenced, padded\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "X_train = pad_sequences(train_seq, maxlen=60)\n",
    "X_test = pad_sequences(test_seq, maxlen=X_train.shape[1])\n",
    "\n",
    "# Word index stored for embedding matrix\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "# Dimensions for embedding matrix\n",
    "embedding_dim = 300\n",
    "vocab_size = min(len(word_index)+1, max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b79eabcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8688, 60)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "79cdc14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution by:\n",
    "    # https://stackoverflow.com/questions/45735070/keras-text-preprocessing-saving-tokenizer-object-to-file-for-scoring\n",
    "\n",
    "#Store tokenizer fit for future preprocessing\n",
    "import pickle\n",
    "\n",
    "# Saved\n",
    "with open('relevance_tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "## Can be loaded for future use:\n",
    "    ## from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "    ## import pickle\n",
    "    ##\n",
    "    ## with open('relevance_tokenizer.pickle', 'rb') as handle:\n",
    "    ##     tokenizer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f2384006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENSIM IMPORT ON GOOGLE PRETRAINED WORD2VEC\n",
    "import gensim.downloader as api\n",
    "wv = api.load('word2vec-google-news-300')\n",
    "    # If you have the physical .bin file downloaded:\n",
    "        # wv = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin',binary=True)\n",
    "\n",
    "    # Empty matrix\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "\n",
    "# Tracking unrecognized words\n",
    "unknown = []\n",
    "\n",
    "# Iterate through fitted word index and\n",
    "# extract weighted vectors from pretrained Google word vector\n",
    "for word, index in word_index.items():\n",
    "    if index >= max_words:\n",
    "        continue\n",
    "    try:\n",
    "        embedding_vector = wv[word] # extract word vector\n",
    "        embedding_matrix[index] = embedding_vector # store word vector\n",
    "    except:\n",
    "        unknown.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e0181b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7059\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['nickcocofree', 'kwxggt', 'nickwilson', 'syvret',\n",
       "       'theresmorewherethatcamefrom', 'nxwestmidlands', 'nurgle',\n",
       "       'dratomic', 'spokane', 'casewrites', 'arobotlegion',\n",
       "       'worldrunners', 'seattletimes', 'sanonofre', 'grumpout',\n",
       "       'originalfunko', 'farrakhan', 'cossackshussars', 'policerun',\n",
       "       'fighterbut'], dtype='<U51')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7059 unrecognized words\n",
    "print(len(unknown))\n",
    "\n",
    "# 20 random unrecognized words\n",
    "np.random.choice(unknown, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a043ce10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train/test:  (8688, 60) (2172, 60)\n",
      "y_train/test:  (8688,) (2172,)\n"
     ]
    }
   ],
   "source": [
    "# Targets converted to arrays\n",
    "y_train = np.asarray(y_train)\n",
    "y_test = np.asarray(y_test)\n",
    "\n",
    "# Shapes\n",
    "print('X_train/test: ', X_train.shape,X_test.shape)\n",
    "print('y_train/test: ', y_train.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063a64da",
   "metadata": {},
   "source": [
    "# 2. MODELING\n",
    "- Deep Neural Network:\n",
    "    - Embedding input layer\n",
    "    - 2 Conv1D layers + 1 Dense layer\n",
    "    - Dense output layer\n",
    "- Previously utilized Bidirectional LSTM instead of second CNN with similar results, but replaced due to ineffient use of memory & computational power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b5c72a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_10 (Embedding)    (None, None, 300)         5660100   \n",
      "                                                                 \n",
      " batch_normalization_28 (Bat  (None, None, 300)        1200      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_27 (Dropout)        (None, None, 300)         0         \n",
      "                                                                 \n",
      " conv1d_15 (Conv1D)          (None, None, 32)          28832     \n",
      "                                                                 \n",
      " batch_normalization_29 (Bat  (None, None, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " average_pooling1d_11 (Avera  (None, None, 32)         0         \n",
      " gePooling1D)                                                    \n",
      "                                                                 \n",
      " dropout_28 (Dropout)        (None, None, 32)          0         \n",
      "                                                                 \n",
      " conv1d_16 (Conv1D)          (None, None, 64)          6208      \n",
      "                                                                 \n",
      " batch_normalization_30 (Bat  (None, None, 64)         256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " global_average_pooling1d_2   (None, 64)               0         \n",
      " (GlobalAveragePooling1D)                                        \n",
      "                                                                 \n",
      " dropout_29 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " batch_normalization_31 (Bat  (None, 32)               128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_30 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,698,965\n",
      "Trainable params: 5,698,109\n",
      "Non-trainable params: 856\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "model = Sequential()\n",
    "\n",
    "# Embedding input\n",
    "model.add(Embedding(vocab_size, embedding_dim, weights=[embedding_matrix],\n",
    "                   trainable=True))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# 1 CNN layers\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(AveragePooling1D())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# 1 CNN layers\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# 1 Dense layer\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "# Sigmoid output\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "# Model Compiled\n",
    "model.compile(loss='binary_crossentropy',\n",
    "             optimizer='SGD',\n",
    "             metrics=['acc'])\n",
    "\n",
    "# Summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a5e0f532",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "136/136 [==============================] - 2s 11ms/step - loss: 0.7890 - acc: 0.5992 - val_loss: 0.6726 - val_acc: 0.5695\n",
      "Epoch 2/200\n",
      "136/136 [==============================] - 1s 6ms/step - loss: 0.6522 - acc: 0.6702 - val_loss: 0.7111 - val_acc: 0.5700\n",
      "Epoch 3/200\n",
      "136/136 [==============================] - 1s 5ms/step - loss: 0.6005 - acc: 0.7032 - val_loss: 0.6237 - val_acc: 0.6381\n",
      "Epoch 4/200\n",
      "136/136 [==============================] - 1s 6ms/step - loss: 0.5645 - acc: 0.7218 - val_loss: 0.5640 - val_acc: 0.7122\n",
      "Epoch 5/200\n",
      "136/136 [==============================] - 1s 5ms/step - loss: 0.5431 - acc: 0.7311 - val_loss: 0.5653 - val_acc: 0.7274\n",
      "Epoch 6/200\n",
      "136/136 [==============================] - 1s 10ms/step - loss: 0.5410 - acc: 0.7379 - val_loss: 0.4824 - val_acc: 0.7841\n",
      "Epoch 7/200\n",
      "136/136 [==============================] - 1s 6ms/step - loss: 0.5218 - acc: 0.7505 - val_loss: 0.5233 - val_acc: 0.7523\n",
      "Epoch 8/200\n",
      "136/136 [==============================] - 1s 6ms/step - loss: 0.5122 - acc: 0.7554 - val_loss: 0.5104 - val_acc: 0.7624\n",
      "Epoch 9/200\n",
      "136/136 [==============================] - 1s 5ms/step - loss: 0.5158 - acc: 0.7545 - val_loss: 0.4716 - val_acc: 0.7758\n",
      "Epoch 10/200\n",
      "136/136 [==============================] - 1s 7ms/step - loss: 0.5028 - acc: 0.7627 - val_loss: 0.5009 - val_acc: 0.7657\n",
      "Epoch 11/200\n",
      "136/136 [==============================] - 1s 7ms/step - loss: 0.5061 - acc: 0.7616 - val_loss: 0.4561 - val_acc: 0.7965\n",
      "Epoch 12/200\n",
      "136/136 [==============================] - 1s 6ms/step - loss: 0.4991 - acc: 0.7669 - val_loss: 0.4776 - val_acc: 0.7767\n",
      "Epoch 13/200\n",
      "136/136 [==============================] - 1s 7ms/step - loss: 0.4926 - acc: 0.7711 - val_loss: 0.4491 - val_acc: 0.7960\n",
      "Epoch 14/200\n",
      "136/136 [==============================] - 1s 8ms/step - loss: 0.4833 - acc: 0.7775 - val_loss: 0.4480 - val_acc: 0.8016\n",
      "Epoch 15/200\n",
      "136/136 [==============================] - 1s 6ms/step - loss: 0.4909 - acc: 0.7744 - val_loss: 0.4838 - val_acc: 0.7776\n",
      "Epoch 16/200\n",
      "136/136 [==============================] - 1s 6ms/step - loss: 0.4905 - acc: 0.7727 - val_loss: 0.4445 - val_acc: 0.7997\n",
      "Epoch 17/200\n",
      "136/136 [==============================] - 1s 6ms/step - loss: 0.4841 - acc: 0.7800 - val_loss: 0.4553 - val_acc: 0.7896\n",
      "Epoch 18/200\n",
      "136/136 [==============================] - 1s 6ms/step - loss: 0.4854 - acc: 0.7789 - val_loss: 0.4634 - val_acc: 0.7864\n",
      "Epoch 19/200\n",
      "136/136 [==============================] - 1s 7ms/step - loss: 0.4799 - acc: 0.7741 - val_loss: 0.4418 - val_acc: 0.7997\n",
      "Epoch 20/200\n",
      "136/136 [==============================] - 1s 5ms/step - loss: 0.4768 - acc: 0.7799 - val_loss: 0.4412 - val_acc: 0.8011\n",
      "Epoch 21/200\n",
      "136/136 [==============================] - 1s 5ms/step - loss: 0.4748 - acc: 0.7872 - val_loss: 0.4406 - val_acc: 0.8071\n",
      "Epoch 22/200\n",
      "136/136 [==============================] - 1s 4ms/step - loss: 0.4714 - acc: 0.7880 - val_loss: 0.4401 - val_acc: 0.8020\n",
      "Epoch 23/200\n",
      "136/136 [==============================] - 1s 7ms/step - loss: 0.4715 - acc: 0.7855 - val_loss: 0.4534 - val_acc: 0.7937\n",
      "Epoch 24/200\n",
      "136/136 [==============================] - 1s 4ms/step - loss: 0.4705 - acc: 0.7878 - val_loss: 0.4365 - val_acc: 0.8025\n",
      "Epoch 25/200\n",
      "136/136 [==============================] - 1s 4ms/step - loss: 0.4707 - acc: 0.7917 - val_loss: 0.4404 - val_acc: 0.8011\n",
      "Epoch 26/200\n",
      "136/136 [==============================] - 1s 6ms/step - loss: 0.4613 - acc: 0.7905 - val_loss: 0.4396 - val_acc: 0.8099\n",
      "Epoch 27/200\n",
      "136/136 [==============================] - 1s 6ms/step - loss: 0.4607 - acc: 0.7917 - val_loss: 0.4560 - val_acc: 0.7937\n",
      "Epoch 28/200\n",
      "136/136 [==============================] - 1s 5ms/step - loss: 0.4636 - acc: 0.7955 - val_loss: 0.4325 - val_acc: 0.8140\n",
      "Epoch 29/200\n",
      "136/136 [==============================] - 1s 8ms/step - loss: 0.4636 - acc: 0.7872 - val_loss: 0.4358 - val_acc: 0.8034\n",
      "Epoch 30/200\n",
      "136/136 [==============================] - 1s 7ms/step - loss: 0.4635 - acc: 0.7889 - val_loss: 0.4288 - val_acc: 0.8158\n",
      "Epoch 31/200\n",
      "136/136 [==============================] - 1s 6ms/step - loss: 0.4594 - acc: 0.7922 - val_loss: 0.4374 - val_acc: 0.8025\n",
      "Epoch 32/200\n",
      "136/136 [==============================] - 1s 7ms/step - loss: 0.4594 - acc: 0.7963 - val_loss: 0.4564 - val_acc: 0.7951\n",
      "Epoch 33/200\n",
      "136/136 [==============================] - 1s 6ms/step - loss: 0.4533 - acc: 0.7957 - val_loss: 0.4278 - val_acc: 0.8145\n",
      "Epoch 34/200\n",
      "136/136 [==============================] - 1s 4ms/step - loss: 0.4580 - acc: 0.7947 - val_loss: 0.4305 - val_acc: 0.8094\n",
      "Epoch 35/200\n",
      "136/136 [==============================] - 1s 5ms/step - loss: 0.4530 - acc: 0.7943 - val_loss: 0.4259 - val_acc: 0.8177\n",
      "Epoch 36/200\n",
      "136/136 [==============================] - 1s 6ms/step - loss: 0.4528 - acc: 0.7945 - val_loss: 0.4248 - val_acc: 0.8172\n",
      "Epoch 37/200\n",
      "136/136 [==============================] - 1s 5ms/step - loss: 0.4594 - acc: 0.7894 - val_loss: 0.4411 - val_acc: 0.8052\n",
      "Epoch 38/200\n",
      "136/136 [==============================] - 1s 5ms/step - loss: 0.4581 - acc: 0.7960 - val_loss: 0.4400 - val_acc: 0.8048\n",
      "Epoch 39/200\n",
      "136/136 [==============================] - 1s 5ms/step - loss: 0.4540 - acc: 0.7968 - val_loss: 0.4334 - val_acc: 0.8117\n",
      "Epoch 40/200\n",
      "136/136 [==============================] - 1s 6ms/step - loss: 0.4518 - acc: 0.7945 - val_loss: 0.4274 - val_acc: 0.8186\n",
      "Epoch 41/200\n",
      "136/136 [==============================] - 1s 5ms/step - loss: 0.4481 - acc: 0.7974 - val_loss: 0.4306 - val_acc: 0.8085\n",
      "Epoch 42/200\n",
      "136/136 [==============================] - 1s 4ms/step - loss: 0.4490 - acc: 0.7994 - val_loss: 0.4221 - val_acc: 0.8214\n",
      "Epoch 43/200\n",
      "136/136 [==============================] - 1s 6ms/step - loss: 0.4506 - acc: 0.8011 - val_loss: 0.4221 - val_acc: 0.8218\n",
      "Epoch 44/200\n",
      "136/136 [==============================] - 1s 8ms/step - loss: 0.4486 - acc: 0.7962 - val_loss: 0.4371 - val_acc: 0.8066\n",
      "Epoch 45/200\n",
      "136/136 [==============================] - 1s 6ms/step - loss: 0.4443 - acc: 0.8052 - val_loss: 0.4202 - val_acc: 0.8172\n",
      "Epoch 46/200\n",
      "136/136 [==============================] - 1s 7ms/step - loss: 0.4460 - acc: 0.8029 - val_loss: 0.4245 - val_acc: 0.8131\n",
      "Epoch 47/200\n",
      "136/136 [==============================] - 1s 6ms/step - loss: 0.4485 - acc: 0.8038 - val_loss: 0.4239 - val_acc: 0.8140\n",
      "Epoch 48/200\n",
      "136/136 [==============================] - 1s 7ms/step - loss: 0.4468 - acc: 0.8036 - val_loss: 0.4292 - val_acc: 0.8099\n",
      "Epoch 49/200\n",
      "136/136 [==============================] - 1s 5ms/step - loss: 0.4487 - acc: 0.7952 - val_loss: 0.4210 - val_acc: 0.8218\n",
      "Epoch 50/200\n",
      "136/136 [==============================] - 1s 5ms/step - loss: 0.4462 - acc: 0.7991 - val_loss: 0.4442 - val_acc: 0.7993\n",
      "Epoch 51/200\n",
      "136/136 [==============================] - 1s 5ms/step - loss: 0.4422 - acc: 0.8038 - val_loss: 0.4214 - val_acc: 0.8135\n",
      "Epoch 52/200\n",
      "136/136 [==============================] - 1s 4ms/step - loss: 0.4394 - acc: 0.8006 - val_loss: 0.4225 - val_acc: 0.8186\n",
      "Epoch 53/200\n",
      "136/136 [==============================] - 1s 5ms/step - loss: 0.4375 - acc: 0.8056 - val_loss: 0.4202 - val_acc: 0.8149\n",
      "Epoch 54/200\n",
      "136/136 [==============================] - 1s 8ms/step - loss: 0.4409 - acc: 0.8047 - val_loss: 0.4180 - val_acc: 0.8168\n",
      "Epoch 55/200\n",
      "136/136 [==============================] - 1s 6ms/step - loss: 0.4392 - acc: 0.8027 - val_loss: 0.4283 - val_acc: 0.8140\n",
      "Epoch 56/200\n",
      "136/136 [==============================] - 1s 4ms/step - loss: 0.4425 - acc: 0.8005 - val_loss: 0.4311 - val_acc: 0.8103\n",
      "Epoch 57/200\n",
      "136/136 [==============================] - 1s 6ms/step - loss: 0.4359 - acc: 0.8055 - val_loss: 0.4195 - val_acc: 0.8181\n",
      "Epoch 58/200\n",
      "136/136 [==============================] - 1s 6ms/step - loss: 0.4367 - acc: 0.8004 - val_loss: 0.4168 - val_acc: 0.8223\n",
      "Epoch 59/200\n",
      "136/136 [==============================] - 1s 10ms/step - loss: 0.4386 - acc: 0.8024 - val_loss: 0.4145 - val_acc: 0.8269\n",
      "Epoch 60/200\n",
      "136/136 [==============================] - 1s 5ms/step - loss: 0.4347 - acc: 0.8095 - val_loss: 0.4239 - val_acc: 0.8135\n",
      "Epoch 61/200\n",
      "136/136 [==============================] - 1s 8ms/step - loss: 0.4367 - acc: 0.8040 - val_loss: 0.4189 - val_acc: 0.8181\n",
      "Epoch 62/200\n",
      "136/136 [==============================] - 1s 7ms/step - loss: 0.4323 - acc: 0.8155 - val_loss: 0.4144 - val_acc: 0.8260\n",
      "Epoch 63/200\n",
      "136/136 [==============================] - 1s 5ms/step - loss: 0.4348 - acc: 0.8044 - val_loss: 0.4179 - val_acc: 0.8172\n",
      "Epoch 64/200\n",
      "136/136 [==============================] - 1s 6ms/step - loss: 0.4382 - acc: 0.8085 - val_loss: 0.4248 - val_acc: 0.8117\n",
      "Epoch 65/200\n",
      "136/136 [==============================] - 1s 5ms/step - loss: 0.4282 - acc: 0.8122 - val_loss: 0.4143 - val_acc: 0.8232\n",
      "Epoch 66/200\n",
      "136/136 [==============================] - 1s 4ms/step - loss: 0.4275 - acc: 0.8119 - val_loss: 0.4173 - val_acc: 0.8181\n",
      "Epoch 67/200\n",
      "136/136 [==============================] - 1s 6ms/step - loss: 0.4307 - acc: 0.8096 - val_loss: 0.4816 - val_acc: 0.7753\n",
      "Epoch 68/200\n",
      "136/136 [==============================] - 1s 5ms/step - loss: 0.4336 - acc: 0.8078 - val_loss: 0.4237 - val_acc: 0.8145\n",
      "Epoch 69/200\n",
      "136/136 [==============================] - 1s 7ms/step - loss: 0.4327 - acc: 0.8097 - val_loss: 0.4153 - val_acc: 0.8195\n",
      "Epoch 70/200\n",
      "136/136 [==============================] - 1s 6ms/step - loss: 0.4272 - acc: 0.8138 - val_loss: 0.4377 - val_acc: 0.8039\n",
      "Epoch 71/200\n",
      "136/136 [==============================] - 1s 5ms/step - loss: 0.4282 - acc: 0.8105 - val_loss: 0.4120 - val_acc: 0.8241\n",
      "Epoch 72/200\n",
      "136/136 [==============================] - 1s 4ms/step - loss: 0.4263 - acc: 0.8141 - val_loss: 0.4257 - val_acc: 0.8154\n",
      "Epoch 73/200\n",
      "136/136 [==============================] - 1s 5ms/step - loss: 0.4257 - acc: 0.8113 - val_loss: 0.4687 - val_acc: 0.7795\n",
      "Epoch 74/200\n",
      "136/136 [==============================] - 1s 6ms/step - loss: 0.4328 - acc: 0.8061 - val_loss: 0.4109 - val_acc: 0.8250\n",
      "Epoch 75/200\n",
      "136/136 [==============================] - 1s 6ms/step - loss: 0.4247 - acc: 0.8112 - val_loss: 0.4110 - val_acc: 0.8264\n",
      "Epoch 76/200\n",
      "136/136 [==============================] - 1s 5ms/step - loss: 0.4204 - acc: 0.8166 - val_loss: 0.4198 - val_acc: 0.8177\n",
      "Epoch 77/200\n",
      "136/136 [==============================] - 1s 6ms/step - loss: 0.4200 - acc: 0.8174 - val_loss: 0.5029 - val_acc: 0.7491\n",
      "Epoch 78/200\n",
      "136/136 [==============================] - 1s 5ms/step - loss: 0.4316 - acc: 0.8135 - val_loss: 0.4114 - val_acc: 0.8241\n",
      "Epoch 79/200\n",
      "136/136 [==============================] - 1s 5ms/step - loss: 0.4239 - acc: 0.8100 - val_loss: 0.4363 - val_acc: 0.8039\n",
      "Epoch 80/200\n",
      "136/136 [==============================] - 1s 5ms/step - loss: 0.4231 - acc: 0.8135 - val_loss: 0.4449 - val_acc: 0.8094\n",
      "Epoch 81/200\n",
      "136/136 [==============================] - 1s 5ms/step - loss: 0.4213 - acc: 0.8151 - val_loss: 0.4101 - val_acc: 0.8283\n",
      "Epoch 82/200\n",
      "136/136 [==============================] - 1s 7ms/step - loss: 0.4156 - acc: 0.8172 - val_loss: 0.4502 - val_acc: 0.8099\n",
      "Epoch 83/200\n",
      "136/136 [==============================] - 1s 4ms/step - loss: 0.4176 - acc: 0.8160 - val_loss: 0.4146 - val_acc: 0.8214\n",
      "Epoch 84/200\n",
      "136/136 [==============================] - 1s 5ms/step - loss: 0.4219 - acc: 0.8148 - val_loss: 0.4101 - val_acc: 0.8246\n",
      "Epoch 85/200\n",
      "136/136 [==============================] - 1s 9ms/step - loss: 0.4189 - acc: 0.8178 - val_loss: 0.4177 - val_acc: 0.8177\n",
      "Epoch 86/200\n",
      "136/136 [==============================] - 1s 4ms/step - loss: 0.4187 - acc: 0.8198 - val_loss: 0.4104 - val_acc: 0.8260\n",
      "Epoch 87/200\n",
      "136/136 [==============================] - 1s 5ms/step - loss: 0.4130 - acc: 0.8224 - val_loss: 0.4244 - val_acc: 0.8172\n",
      "Epoch 88/200\n",
      "136/136 [==============================] - 1s 7ms/step - loss: 0.4170 - acc: 0.8195 - val_loss: 0.4139 - val_acc: 0.8218\n",
      "Epoch 89/200\n",
      "136/136 [==============================] - 1s 6ms/step - loss: 0.4165 - acc: 0.8204 - val_loss: 0.4188 - val_acc: 0.8158\n",
      "Epoch 90/200\n",
      "136/136 [==============================] - 1s 9ms/step - loss: 0.4128 - acc: 0.8202 - val_loss: 0.4209 - val_acc: 0.8154\n",
      "Epoch 91/200\n",
      "136/136 [==============================] - 1s 6ms/step - loss: 0.4111 - acc: 0.8193 - val_loss: 0.4224 - val_acc: 0.8168\n",
      "Epoch 92/200\n",
      "136/136 [==============================] - 1s 5ms/step - loss: 0.4095 - acc: 0.8212 - val_loss: 0.4129 - val_acc: 0.8250\n",
      "Epoch 93/200\n",
      "136/136 [==============================] - 1s 4ms/step - loss: 0.4197 - acc: 0.8169 - val_loss: 0.4510 - val_acc: 0.7970\n",
      "Epoch 94/200\n",
      "136/136 [==============================] - 1s 6ms/step - loss: 0.4152 - acc: 0.8215 - val_loss: 0.4098 - val_acc: 0.8264\n",
      "Epoch 95/200\n",
      "136/136 [==============================] - 1s 7ms/step - loss: 0.4141 - acc: 0.8208 - val_loss: 0.4108 - val_acc: 0.8250\n",
      "Epoch 96/200\n",
      "136/136 [==============================] - 1s 6ms/step - loss: 0.4149 - acc: 0.8194 - val_loss: 0.4232 - val_acc: 0.8168\n",
      "Epoch 97/200\n",
      "136/136 [==============================] - 1s 4ms/step - loss: 0.4106 - acc: 0.8211 - val_loss: 0.4109 - val_acc: 0.8214\n",
      "Epoch 98/200\n",
      "136/136 [==============================] - 1s 5ms/step - loss: 0.4110 - acc: 0.8217 - val_loss: 0.4324 - val_acc: 0.8145\n",
      "Epoch 99/200\n",
      "136/136 [==============================] - 2s 12ms/step - loss: 0.4080 - acc: 0.8227 - val_loss: 0.4100 - val_acc: 0.8241\n",
      "Epoch 100/200\n",
      "136/136 [==============================] - 1s 6ms/step - loss: 0.4128 - acc: 0.8224 - val_loss: 0.4583 - val_acc: 0.7882\n",
      "Epoch 101/200\n",
      "136/136 [==============================] - 1s 6ms/step - loss: 0.4070 - acc: 0.8250 - val_loss: 0.4156 - val_acc: 0.8181\n",
      "Epoch 102/200\n",
      "136/136 [==============================] - 1s 5ms/step - loss: 0.4107 - acc: 0.8206 - val_loss: 0.4067 - val_acc: 0.8283\n",
      "Epoch 103/200\n",
      "136/136 [==============================] - 1s 9ms/step - loss: 0.4042 - acc: 0.8249 - val_loss: 0.4084 - val_acc: 0.8246\n",
      "Epoch 104/200\n",
      "136/136 [==============================] - 1s 11ms/step - loss: 0.4052 - acc: 0.8224 - val_loss: 0.4186 - val_acc: 0.8195\n",
      "Epoch 105/200\n",
      "136/136 [==============================] - 1s 11ms/step - loss: 0.4150 - acc: 0.8195 - val_loss: 0.4075 - val_acc: 0.8237\n",
      "Epoch 106/200\n",
      "136/136 [==============================] - 1s 6ms/step - loss: 0.4061 - acc: 0.8242 - val_loss: 0.4319 - val_acc: 0.8154\n",
      "Epoch 107/200\n",
      "136/136 [==============================] - 1s 8ms/step - loss: 0.4023 - acc: 0.8256 - val_loss: 0.4060 - val_acc: 0.8269\n",
      "Epoch 108/200\n",
      "136/136 [==============================] - 1s 9ms/step - loss: 0.3981 - acc: 0.8308 - val_loss: 0.4358 - val_acc: 0.8158\n",
      "Epoch 109/200\n",
      "136/136 [==============================] - 1s 6ms/step - loss: 0.4021 - acc: 0.8246 - val_loss: 0.4301 - val_acc: 0.8168\n",
      "Epoch 110/200\n",
      "136/136 [==============================] - 1s 11ms/step - loss: 0.4090 - acc: 0.8241 - val_loss: 0.4190 - val_acc: 0.8200\n",
      "Epoch 111/200\n",
      "136/136 [==============================] - 1s 8ms/step - loss: 0.4087 - acc: 0.8221 - val_loss: 0.4061 - val_acc: 0.8278\n",
      "Epoch 112/200\n",
      "136/136 [==============================] - 1s 4ms/step - loss: 0.4044 - acc: 0.8299 - val_loss: 0.4069 - val_acc: 0.8273\n",
      "Epoch 113/200\n",
      "136/136 [==============================] - 1s 7ms/step - loss: 0.4016 - acc: 0.8303 - val_loss: 0.4063 - val_acc: 0.8273\n",
      "Epoch 114/200\n",
      "136/136 [==============================] - 1s 5ms/step - loss: 0.4020 - acc: 0.8290 - val_loss: 0.4077 - val_acc: 0.8273\n",
      "Epoch 115/200\n",
      "136/136 [==============================] - 1s 8ms/step - loss: 0.4019 - acc: 0.8299 - val_loss: 0.4989 - val_acc: 0.7500\n",
      "Epoch 116/200\n",
      "136/136 [==============================] - 1s 8ms/step - loss: 0.4029 - acc: 0.8264 - val_loss: 0.4129 - val_acc: 0.8232\n",
      "Epoch 117/200\n",
      "136/136 [==============================] - 1s 6ms/step - loss: 0.4009 - acc: 0.8279 - val_loss: 0.4060 - val_acc: 0.8273\n",
      "Epoch 118/200\n",
      "136/136 [==============================] - 1s 5ms/step - loss: 0.4041 - acc: 0.8276 - val_loss: 0.4057 - val_acc: 0.8269\n",
      "Epoch 119/200\n",
      "136/136 [==============================] - 1s 4ms/step - loss: 0.4023 - acc: 0.8264 - val_loss: 0.4071 - val_acc: 0.8273\n",
      "Epoch 120/200\n",
      "136/136 [==============================] - 1s 7ms/step - loss: 0.3910 - acc: 0.8323 - val_loss: 0.4284 - val_acc: 0.8131\n",
      "Epoch 121/200\n",
      "136/136 [==============================] - 1s 10ms/step - loss: 0.3982 - acc: 0.8279 - val_loss: 0.5100 - val_acc: 0.7864\n",
      "Epoch 122/200\n",
      "136/136 [==============================] - 1s 6ms/step - loss: 0.3987 - acc: 0.8298 - val_loss: 0.4113 - val_acc: 0.8237\n",
      "Epoch 123/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136/136 [==============================] - 1s 8ms/step - loss: 0.3926 - acc: 0.8321 - val_loss: 0.4229 - val_acc: 0.8200\n",
      "Epoch 124/200\n",
      "136/136 [==============================] - 1s 10ms/step - loss: 0.3941 - acc: 0.8323 - val_loss: 0.4415 - val_acc: 0.8172\n",
      "Epoch 125/200\n",
      "136/136 [==============================] - 1s 9ms/step - loss: 0.3936 - acc: 0.8313 - val_loss: 0.4078 - val_acc: 0.8306\n",
      "Epoch 126/200\n",
      "136/136 [==============================] - 1s 11ms/step - loss: 0.3911 - acc: 0.8337 - val_loss: 0.4065 - val_acc: 0.8315\n",
      "Epoch 127/200\n",
      "136/136 [==============================] - 1s 5ms/step - loss: 0.3900 - acc: 0.8300 - val_loss: 0.4106 - val_acc: 0.8278\n",
      "Epoch 128/200\n",
      "136/136 [==============================] - 1s 4ms/step - loss: 0.3927 - acc: 0.8330 - val_loss: 0.4084 - val_acc: 0.8310\n",
      "Epoch 129/200\n",
      "136/136 [==============================] - 1s 5ms/step - loss: 0.3918 - acc: 0.8354 - val_loss: 0.4055 - val_acc: 0.8310\n",
      "Epoch 130/200\n",
      "136/136 [==============================] - 1s 10ms/step - loss: 0.3952 - acc: 0.8305 - val_loss: 0.4100 - val_acc: 0.8260\n",
      "Epoch 131/200\n",
      "136/136 [==============================] - 1s 8ms/step - loss: 0.3876 - acc: 0.8315 - val_loss: 0.4071 - val_acc: 0.8260\n",
      "Epoch 132/200\n",
      "136/136 [==============================] - 1s 9ms/step - loss: 0.3842 - acc: 0.8393 - val_loss: 0.4092 - val_acc: 0.8306\n",
      "Epoch 133/200\n",
      "136/136 [==============================] - 1s 4ms/step - loss: 0.3927 - acc: 0.8257 - val_loss: 0.4192 - val_acc: 0.8214\n",
      "Epoch 134/200\n",
      "136/136 [==============================] - 2s 14ms/step - loss: 0.3882 - acc: 0.8359 - val_loss: 0.4065 - val_acc: 0.8324\n",
      "Epoch 135/200\n",
      "136/136 [==============================] - 2s 11ms/step - loss: 0.3893 - acc: 0.8310 - val_loss: 0.4561 - val_acc: 0.7919\n",
      "Epoch 136/200\n",
      "136/136 [==============================] - 1s 5ms/step - loss: 0.3880 - acc: 0.8358 - val_loss: 0.4329 - val_acc: 0.8163\n",
      "Epoch 137/200\n",
      "136/136 [==============================] - 2s 13ms/step - loss: 0.3844 - acc: 0.8379 - val_loss: 0.4617 - val_acc: 0.7859\n",
      "Epoch 138/200\n",
      "136/136 [==============================] - 1s 6ms/step - loss: 0.3866 - acc: 0.8326 - val_loss: 0.4231 - val_acc: 0.8200\n",
      "Epoch 139/200\n",
      "136/136 [==============================] - 1s 5ms/step - loss: 0.3847 - acc: 0.8407 - val_loss: 0.4397 - val_acc: 0.8168\n",
      "Epoch 140/200\n",
      "136/136 [==============================] - 1s 4ms/step - loss: 0.3842 - acc: 0.8352 - val_loss: 0.4348 - val_acc: 0.8168\n",
      "Epoch 141/200\n",
      "136/136 [==============================] - 2s 11ms/step - loss: 0.3835 - acc: 0.8382 - val_loss: 0.4056 - val_acc: 0.8310\n",
      "Epoch 142/200\n",
      "136/136 [==============================] - 1s 6ms/step - loss: 0.3836 - acc: 0.8366 - val_loss: 0.4103 - val_acc: 0.8273\n",
      "Epoch 143/200\n",
      "136/136 [==============================] - 1s 7ms/step - loss: 0.3831 - acc: 0.8351 - val_loss: 0.4521 - val_acc: 0.8080\n",
      "Epoch 144/200\n",
      "136/136 [==============================] - 1s 6ms/step - loss: 0.3828 - acc: 0.8375 - val_loss: 0.4056 - val_acc: 0.8343\n",
      "Epoch 145/200\n",
      "136/136 [==============================] - 1s 7ms/step - loss: 0.3830 - acc: 0.8363 - val_loss: 0.4142 - val_acc: 0.8232\n",
      "Epoch 146/200\n",
      "136/136 [==============================] - 1s 4ms/step - loss: 0.3837 - acc: 0.8372 - val_loss: 0.4183 - val_acc: 0.8246\n",
      "Epoch 147/200\n",
      "136/136 [==============================] - 1s 7ms/step - loss: 0.3759 - acc: 0.8379 - val_loss: 0.4681 - val_acc: 0.7896\n",
      "Epoch 148/200\n",
      "136/136 [==============================] - 1s 8ms/step - loss: 0.3813 - acc: 0.8346 - val_loss: 0.4094 - val_acc: 0.8269\n",
      "Epoch 149/200\n",
      "136/136 [==============================] - 1s 7ms/step - loss: 0.3773 - acc: 0.8395 - val_loss: 0.4098 - val_acc: 0.8310\n",
      "Epoch 150/200\n",
      "136/136 [==============================] - 1s 7ms/step - loss: 0.3816 - acc: 0.8377 - val_loss: 0.4081 - val_acc: 0.8315\n",
      "Epoch 151/200\n",
      "136/136 [==============================] - 1s 5ms/step - loss: 0.3788 - acc: 0.8424 - val_loss: 0.4090 - val_acc: 0.8315\n",
      "Epoch 152/200\n",
      "136/136 [==============================] - 2s 12ms/step - loss: 0.3754 - acc: 0.8397 - val_loss: 0.4076 - val_acc: 0.8273\n",
      "Epoch 153/200\n",
      "136/136 [==============================] - 1s 5ms/step - loss: 0.3800 - acc: 0.8379 - val_loss: 0.4092 - val_acc: 0.8269\n",
      "Epoch 154/200\n",
      "136/136 [==============================] - 1s 6ms/step - loss: 0.3830 - acc: 0.8374 - val_loss: 0.4271 - val_acc: 0.8237\n"
     ]
    }
   ],
   "source": [
    "# Early stop 25 epochs after lowest validation, best weights restored\n",
    "early = EarlyStopping(monitor='val_loss', patience=25, min_delta = 0.0001, restore_best_weights=True)\n",
    "\n",
    "# Store best weights for future use without re-training\n",
    "filepath = \"weights/weights-improvement-{epoch:02d}-{val_loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, mode='min', save_weights_only=True)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    batch_size=64,\n",
    "                    epochs=200,\n",
    "                    callbacks=[early, checkpoint],\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc0064d",
   "metadata": {},
   "source": [
    "## 2.1 RESULTS\n",
    "### || CNN || SGD || Google W2V weights || Dropout= 0.5embedding/0.25CNN/0.4Dense || Filters=32CNN/64CNN/32Dense ||\n",
    "    \n",
    "- **SDG**\n",
    "    - loss: 0.3918 - acc: 0.8354 - val_loss: 0.4055 - val_acc: 0.8310"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa423e10",
   "metadata": {},
   "source": [
    "### 2.2 MODEL SAVING FOR RE-USE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6a27b336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload best weight from epoch 129/200\n",
    "model.load_weights('weights/weights-improvement-129-0.4055.hdf5')\n",
    "\n",
    "# Save model\n",
    "model.save('pretrained_models/relevance_model.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa91e5b9",
   "metadata": {},
   "source": [
    "### TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3f8e7461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword  ... target predictions\n",
       "0   1     NaN  ...      1           1\n",
       "1   4     NaN  ...      1           1\n",
       "2   5     NaN  ...      1           1\n",
       "3   6     NaN  ...      1           1\n",
       "4   7     NaN  ...      1           1\n",
       "\n",
       "[5 rows x 6 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9f132493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST RESULTS\n",
      "ACCURACY: 0.7128712871287128\n",
      "F1 SCORE: 0.6233766233766234\n",
      "ROC AUC: 0.7105882352941176\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test on Kaggle competition dataset\n",
    "    # A different kaggle dataset that also has disaster tweets\n",
    "test = pd.read_csv('../datasets/validation_data.csv')\n",
    "\n",
    "# Preprocessing\n",
    "text_raw = test['text']\n",
    "test_cleaned = text_raw.apply(clean).apply(clean2).apply(clean3)\n",
    "test_seq = tokenizer.texts_to_sequences(test_cleaned)\n",
    "test_padded = pad_sequences(test_seq, maxlen=60)\n",
    "\n",
    "# Predictions\n",
    "test['predictions'] = (model.predict(test_padded)>0.5).astype(int)\n",
    "\n",
    "# Scores\n",
    "acc = accuracy_score(test['disaster_related'], test['predictions'])\n",
    "f1 = f1_score(test['disaster_related'], test['predictions'])\n",
    "roc_auc = roc_auc_score(test['disaster_related'], test['predictions'])\n",
    "\n",
    "print('TEST RESULTS')\n",
    "print(f'ACCURACY: {acc}')\n",
    "print(f'F1 SCORE: {f1}')\n",
    "print(f'ROC AUC: {roc_auc}')\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(test['disaster_related'], test['predictions'])\n",
    "sns.heatmap(cm, cmap= 'cividis', annot=True, fmt='g', annot_kws={'size':20})\n",
    "plt.xlabel('predicted', fontsize=18)\n",
    "plt.ylabel('actual', fontsize=18)\n",
    "plt.title('Test Actual vs Predicted', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5d598925",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-06 23:18:58.381975: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 22640400 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST RESULTS\n",
      "ACCURACY: 0.8645737554183633\n",
      "F1 SCORE: 0.8284811179504241\n",
      "ROC AUC: 0.8518289714576444\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test on Kaggle competition dataset\n",
    "    # A different kaggle dataset that also has disaster tweets\n",
    "test = pd.read_csv('../datasets/disaster_competition.csv')\n",
    "\n",
    "# Preprocessing\n",
    "text_raw = test['text']\n",
    "test_cleaned = text_raw.apply(clean).apply(clean2).apply(clean3)\n",
    "test_seq = tokenizer.texts_to_sequences(test_cleaned)\n",
    "test_padded = pad_sequences(test_seq, maxlen=60)\n",
    "\n",
    "# Predictions\n",
    "test['predictions'] = (model.predict(test_padded)>0.5).astype(int)\n",
    "\n",
    "# Scores\n",
    "acc = accuracy_score(test['target'], test['predictions'])\n",
    "f1 = f1_score(test['target'], test['predictions'])\n",
    "roc_auc = roc_auc_score(test['target'], test['predictions'])\n",
    "\n",
    "print('TEST RESULTS')\n",
    "print(f'ACCURACY: {acc}')\n",
    "print(f'F1 SCORE: {f1}')\n",
    "print(f'ROC AUC: {roc_auc}')\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(test['target'], test['predictions'])\n",
    "sns.heatmap(cm, cmap= 'cividis', annot=True, fmt='g', annot_kws={'size':20})\n",
    "plt.xlabel('predicted', fontsize=18)\n",
    "plt.ylabel('actual', fontsize=18)\n",
    "plt.title('Test Actual vs Predicted', fontsize=18)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
